{
  "size": 0,
  "query": {
    "function_score": {
      "random_score": {}
    }
  },
  "aggs": {
    "random_sample": {
      "sampler": {
        "shard_size": 2000
      },
      "aggs": {
        "frequent_sets": {
          "scripted_metric": {
            "params": {
                "fields": ["f1", "f2", "f3", "f4", "f5", "f6"],
                "min_support": 0.1,
                "max_set_size": 4
            },
            "init_script": "state.uniques = new HashMap()",
            "map_script": """
              def key = [];
              for (field in params["fields"]) {
                // In a scripted metric aggregation each document is provided as a doc
                // variable to the map_script. One can check for the existence of fields
                // in doc as follows.
                if (doc[field].size() > 0) {
                    key.add(doc[field].getValue());
                }
              }
              Collections.sort(key);
              def flatKey = new StringJoiner(" ");
              for (item in key) {
                flatKey.add(item);
              }
              int count = state.uniques.getOrDefault(flatKey.toString(), 0);
              state.uniques.put(flatKey.toString(), count + 1);
            """,
            "combine_script": "return state",
            "reduce_script": """
              def reducedState = new HashMap();
              // In a scripted metric aggregation the states variable is a list of the
              // objects returned by the combine_script from each shard.
              for (state in states) {
                for (items in state.uniques.entrySet()) {
                  int count = reducedState.getOrDefault(items.getKey(), 0);
                  reducedState.put(items.getKey(), count + items.getValue());
                }
              }

              def uniqueItemSets = [];
              for (items in reducedState.entrySet()) {
                def itemSet = new HashSet();
                def tokenizer = new StringTokenizer(items.getKey(), " ");
                while (tokenizer.hasMoreElements()) {
                  itemSet.add(tokenizer.nextToken());
                }
                uniqueItemSets.add([itemSet, items.getValue()]);
              }

              // If you can convert a list item to an ordinal it is possible to sort the list
              // using a Java lambda to perform this conversion. Here, we sort in decending
              // order of count so we can break out of the inner loop below by testing an upper
              // bound for the support.
              def countOrder = Comparator.comparing(set -> set[1]);
              uniqueItemSets.sort(countOrder.reversed());

              int totalCount = 0;
              def uniqueItems = new HashMap();
              for (int i = uniqueItemSets.size(); i-- > 0; ) {
                uniqueItemSets[i].add(totalCount);
                for (item in uniqueItemSets[i][0]) {
                  int count = uniqueItems.getOrDefault(item, 0);
                  uniqueItems.put(item, count + uniqueItemSets[i][1]);
                }
                totalCount = totalCount + uniqueItemSets[i][1];
              }

              def frequentSets = [new HashMap()];
              for (item in uniqueItems.entrySet()) {
                if (item.getValue() > params["min_support"] * totalCount) {
                  frequentSets[0].put(item.getKey(), ((double)item.getValue()) / totalCount);
                }
              }

              for (int k = 0; k < params["max_set_size"]; k++) {
                // Build the frequent sets k + 1 by extending frequent sets of size k.
                def frequentSetsKPlus1 = new HashMap();
                for (rule in frequentSets[k].entrySet()) {
                  def tokenizer = new StringTokenizer(rule.getKey(), " ");
                  def frequentSetItems = Collections.list(tokenizer);

                  // By the downward closure lemma we need only consider extending the set
                  // with items which individually have sufficient support.
                  for (item in frequentSets[0].entrySet()) {
                    if (frequentSetItems.contains(item.getKey())) {
                      continue;
                    }

                    def extendedFrequentSetItems = new ArrayList(frequentSetItems);
                    extendedFrequentSetItems.add(item.getKey());
                    Collections.sort(extendedFrequentSetItems);
                    int support = 0;
                    for (unique in uniqueItemSets) {
                      if (unique[0].containsAll(extendedFrequentSetItems)) {
                        support = support + unique[1];
                      }
                      // unique[2] is the sum of all remaining unique item set counts and
                      // so provides an upper bound for the final support for this set.
                      if (support + unique[2] < params["min_support"] * totalCount) {
                        break;
                      }
                    }
                    if (support > params["min_support"] * totalCount) {
                      def flatExtendedRule = new StringJoiner(" ");
                      for (ruleItem in extendedFrequentSetItems) {
                        flatExtendedRule.add(ruleItem);
                      }
                      frequentSetsKPlus1.put(flatExtendedRule.toString(), ((double)support) / totalCount);
                    }
                  }
                }
                frequentSets.add(frequentSetsKPlus1);
              }
              return frequentSets;
            """
          }
        }
      }
    }
  }
}